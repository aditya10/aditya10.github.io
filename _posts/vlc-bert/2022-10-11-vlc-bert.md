---
layout: post
title:  "VLC-BERT: Visual Question Answering with Contextualized Commonsense Knowledge"
date:   2022-10-24 09:29:20 +0700
categories: projects
category: publication
authors: "Sahithya Ravi*, Aditya Chinchure*, Leonid Sigal, Renjie Liao, Vered Schwartz (*equal contribution)"
conference: "WACV 2023"
image: assets/posts/vlc-bert/vlc-bert.png
description: We present a new Vision-Language-Commonsense transformer model, VLC-BERT, that incorporates contextualized knowledge using Commonsense Transformer (COMET) to solve Visual Question Answering (VQA) tasks that require commonsense reasoning.
---
We present a new Vision-Language-Commonsense transformer model, VLC-BERT, that incorporates contextualized knowledge using Commonsense Transformer (COMET) to solve Visual Question Answering (VQA) tasks that require commonsense reasoning. VLC-BERT outperforms existing models that utilize static knowledge bases, and the article provides a detailed analysis of which questions benefit from the contextualized commonsense knowledge from COMET.