---
title: Aditya Chinchure
permalink: /
layout: master
excerpt: 
comments: false
home: true
---

I’m a Computer Science student at the University of British Columbia, Vancouver. I work in the Computer Vision Lab with Dr. Leonid Sigal and Dr. Renjie Liao. My interests lie in multimodal vision-language models, time-series models, and commonsense reasoning. 

In addition, I am a photographer in the city. I enjoy doing landscape and product photography. My work has over 100 million views on Unsplash.

If you are reading this, I would love to talk to you! I am always looking for opportunities to collaborate on photography or computer science projects. Also, my inbox is open if you have any questions about student life at UBC or Vancouver. Message me on Instagram or send me an email anytime.

## Publications

**VLC-BERT: Visual Question Answering with Contextualized Commonsense Knowledge** \
Sahithya Ravi\*, **Aditya Chinchure**\*, Leonid Sigal, Renjie Liao, Vered Shwartz (\* equal) \
_Accepted at WACV 2023_ \
[arXiv](https://arxiv.org/abs/2210.13626) | [Code](https://github.com/aditya10/VLC-BERT)


## Work

**Undergraduate Research Assistant, LEAP Project at UBC Computer Science** \
_Vancouver | May 2020 - August 2020_ \
Working on backend projects for LEAP, a differential privacy-focused federated data analytics platform.

**Machine Learning Engineer (Co-op), SoapBox** \
_Toronto | May 2019 - August 2019_ \
Developed machine learning models for text classification, sentiment analysis and entity recognition using PyTorch, fast.ai and RASA NLU

**Junior Software Developer (Co-op), AppNeta** \
_Vancouver | September 2018 – April 2019_ \
Worked in a team of eight to scale up our application for cloud deployments. 

## Education

**MSc. in Computer Science** \
The University of British Columbia |
2021 - 2023

**BSc. Honours in Computer Science** \
The University of British Columbia | 
2016 - 2021 |  GPA: 88% \
International Student – Faculty of Science Scholarship & Dean’s Honour List

## Projects

**Graph-enhanced Transformers for Referring Expressions Comprehension** \
We explore a simple method to incorporate inter-token relationships in a Transformer before performing any training, using graphs with edge features. In VL-BERT-Graph, we generate a fully-connected graph of input tokens where the edges represent similarity between the tokens, obtained using GloVE and CLIP. We then use a message-passing GNN to incorporate these features into the input tokens or the output encoding of the model, and train the Transformer with edge-feature attention masks.

**A Summary of Recent Text Summarization Techniques** \
In this project paper, we surveyed text summarization models by evaluating existing extractive and abstractive models. We studied the metrics and datasets used to evaluate the latest models and evaluated upcoming abstractive techniques. Finally, we highlighted future pathways for text summarization and suggested areas for improvement.

**Universal Machine Learning API** \
A powerful Python API template, built on Flask, for plug-and-play use with machine learning models. \
_Technologies used: Python, with the Flask API package_

**BERT Transformer based Text Classifier using TensorFlow** \
A multi-class text classification example on the StackOverflow Questions dataset. \
_Technologies used: Python, with Pandas, TensorFlow_
