---
title: Aditya Chinchure
permalink: /
layout: master
excerpt: 
comments: false
home: true
---

üëã Hello there! 

I am a PhD student at the Computer Vision and NLP Labs at University of British Columbia. I am fortunate to be advised by [Dr. Leonid Sigal](https://www.cs.ubc.ca/~lsigal/index.html) and [Dr. Vered Shwartz](https://www.cs.ubc.ca/~vshwartz/), and supported by the highly competitive [UBC Four Year Fellowship (4YF)](https://www.grad.ubc.ca/awards/four-year-doctoral-fellowship-4yf).

My research focus is on applying methods from _human reasoning and cognition_ to develop vision-language models üëÅÔ∏è and evaluation tools üõ†Ô∏è. I have worked on image and video understanding & reasoning, as well as bias and fairness in Generative AI.

I am an incoming research intern at [Ideogram](https://ideogram.ai/t/explore). Previously, I was a visiting scholar at [Toyota Technological Institute at Chicago](https://ttic.edu), working with [Dr. Matthew Turk](https://home.ttic.edu/~mturk/), and an intern at [Borealis AI](https://www.borealisai.com) with [Dr. Fred Tung](https://www.borealisai.com/team-member/fred-tung/). In addition, I enjoy doing photography as a hobby. My work has over [200 million views on Unsplash](https://unsplash.com/@adityachinchure). You can find my latest photos on [Instagram](https://www.instagram.com/jpgs.by.adi/).

If you are reading this, I would love to talk to you! I am always looking for opportunities to collaborate. Also, my inbox is open if you have any questions about student life at UBC or Vancouver. Message me on [Instagram](https://www.instagram.com/jpgs.by.adi/) or send me an [email](mailto:aditya.chinchure+web@gmail.com).

<a class="link-button" href="assets/AdityaChinchure-Resume.pdf">Resume</a> ‚Ä¢ <a class="link-button" href="/projects">Projects</a> ‚Ä¢ <a class="link-button" href="https://www.linkedin.com/in/adityachinchure/">LinkedIn</a>


## üóûÔ∏è News

* [2025/09] Pre-print of our work, [SPIKE-RL: Video-LLMs meet Bayesian Surprise](https://www.arxiv.org/abs/2509.23433), is now available on ArXiv!
* [2025/09] üéâ Our position paper, [World Models must live in Parallel Worlds](assets/Position__World_Models_must_live_in_parallel_worlds_arxiv.pdf), accepted at NeurIPS 2025 Workshop on Bridging Language, Agent, and World Models for Reasoning (LAW 2025).
* [2025/08] üéâ Our paper [Mitigate One, Skew Another? Tackling Intersectional Biases in Text-to-Image Models](https://arxiv.org/abs/2505.17280) is accepted at EMNLP 2025!
* [2025/08] Presented Black Swan at [Vector Institute‚Äôs Endless Summer School](https://vectorinstitute.ai/event/endless-summer-school-multimodal-and-foundation-models/)
* [2025/07] Attending & presenting our work on bias detection and video reasoning in text-to-image models at [Vision & Learning Workshop](https://sites.google.com/view/vancouver-icml2025/) @ ICML 2025!
* [2025/06] ‚≠ê Awarded outstanding reviewer @ CVPR 2025. Attending CVPR in Nashville.
* [2025/04] üî• Among 30 researchers from Canada, including Yoshua Bengio, to attend the [Safety-Guaranteed LLMs](https://simons.berkeley.edu/workshops/safety-guaranteed-llms) workshop at Simons Institute, UC Berekely!
* [2025/02] üéâ Our paper [Black Swan: Abductive and Defeasible Video Reasoning in Unpredictable Events](http://blackswan.cs.ubc.ca/) is accepted at CVPR 2025!
* [2025/01] üéß Our work on [Biases in Image Generation AI](https://tibet-ai.github.io) is [featured on the Knowledge at Wharton podcast](https://www.youtube.com/watch?v=zfdPb3DLqXA)!
* [2024/10] üìö Joining Toyota Technological Institute at Chicago (TTIC) as a Visiting Researcher, working with Dr. Matthew Turk
* [2024/10] üéâ [From Local Concepts to Universals: Evaluating the Multicultural Understanding of VL Models](https://arxiv.org/abs/2407.00263) is accepted at EMNLP 2024!
* [2024/07] üéâ Our paper [TIBET: Identifying and Evaluating Biases in T2I models](https://tibet-ai.github.io) is accepted at ECCV 2024!

[üì£ See More](/news)

## üìö Publications

**SPIKE-RL: Video-LLMs meet Bayesian Surprise** \
Sahithya Ravi, **Aditya Chinchure**, Raymond Ng, Leonid Sigal, Vered Shwartz \
_Preprint_ \
[arXiv](https://www.arxiv.org/abs/2509.23433) 

**Position: World Models must live in Parallel Worlds** \
Sahithya Ravi\*, **Aditya Chinchure**\*, Pushkar Shukla, Vered Shwartz, Leonid Sigal (\* equal) \
_Accepted at NeurIPS 2025 Workshop on Bridging Language, Agent, and World Models for Reasoning and Planning (LAW)_ \
[paper](assets/Position__World_Models_must_live_in_parallel_worlds_arxiv.pdf)

**Mitigate One, Skew Another? Tackling Intersectional Biases in Text-to-Image Models** \
Pushkar Shukla\*, **Aditya Chinchure**\*, Emily Diana, Alexander Tolbert, Kartik Hosanagar, Vineeth Balasubramanian, Leonid Sigal, Matthew Turk (\* equal) \
_Accepted at EMNLP 2025 (Findings)_ \
[arXiv](https://arxiv.org/abs/2505.17280)

**Black Swan: Abductive and Defeasible Video Reasoning in Unpredictable Events** \
**Aditya Chinchure**\*, Sahithya Ravi\*, Raymond Ng, Vered Shwartz, Boyang Li, Leonid Sigal (\* equal) \
_Accepted at CVPR 2025_ \
[arXiv](https://arxiv.org/abs/2412.05725) | [Website](https://blackswan.cs.ubc.ca)

**From Local Concepts to Universals: Evaluating the Multicultural Understanding of Vision-Language Models** \
Mehar Bhatia, Sahithya Ravi\*, **Aditya Chinchure**\*, Eunjeong Hwang, Vered Shwartz (\* equal) \
_Accepted at EMNLP 2024_ \
[arXiv](https://arxiv.org/abs/2407.00263) | [Website](https://globalrg.github.io)

**TIBET: Identifying and Evaluating Biases in Text-to-Image Generative Models** \
**Aditya Chinchure**\*, Pushkar Shukla\*, Gaurav Bhatt, Kiri Salij, Kartik Hosanagar, Leonid Sigal, Matthew Turk (\* equal) \
_Accepted at ECCV 2024_ \
[arXiv](https://arxiv.org/abs/2312.01261) | [Website](https://tibet-ai.github.io)

**Visual Question Answering with Contextualized Commonsense Knowledge [Masters Thesis]** \
**Aditya Chinchure** \
[UBC Library](https://open.library.ubc.ca/soa/cIRcle/collections/ubctheses/24/items/1.0441296)

**VLC-BERT: Visual Question Answering with Contextualized Commonsense Knowledge** \
Sahithya Ravi\*, **Aditya Chinchure**\*, Leonid Sigal, Renjie Liao, Vered Shwartz (\* equal) \
_Accepted at WACV 2023_ \
[arXiv](https://arxiv.org/abs/2210.13626) | [Code](https://github.com/aditya10/VLC-BERT)

**Refinement Architectures for Referring Image Segmentation [Honours Thesis]** \
**Aditya Chinchure** \
[Thesis](https://drive.google.com/file/d/1cU3ysSpXoYRvUslg4RIENoS7O3-lV0sb/view?usp=sharing)

**LEAP: Private and Federated Data Analysis for Healthcare** \
Matheus Stolet, Chris Yoon, Kalli Leung, **Aditya Chinchure**, Mathias L√©cuyer, Aline Talhouk, Ivan Beschastnikh \
_Poster at Emerging Technologies: BC's AI Showcase, organized by UBC's Centre for Artificial Intelligence Decision-making and Action (CAIDA)_ \
[Website](https://leap-project.github.io)

## üåé Collaborators

> _"It takes a village to raise a child, and a brilliant team (and lots of caffine) to raise a PhD"_

Apart from my supervisors, I have had the pleasure of collaborating with:

* [Sahithya Ravi](https://sahithyaravi.github.io/) (UBC NLP)
* [Pushkar Shukla](https://pushkershukla.github.io) (TTIC)
* [Matthew Turk](https://home.ttic.edu/~mturk/) (TTIC)
* [Kartik Hosanagar](http://www.hosanagar.com) (Wharton)
* [Vineeth Balasubramanian](https://people.iith.ac.in/vineethnb/) (Microsoft Research)
* [Boyang (Albert) Li](http://www.boyangli.org) (NTU Singapore)
* [Renjie Liao](https://lrjconan.github.io) (UBC ECE)
* [Mehar Bhatia](https://meharbhatia.github.io) (Mila)
* [Gaurav Bhatt](https://gauravbh1010tt.github.io) (UBC CV) 

... and many more.

## üìë Reviewing

I have reviewed several papers for: NeurIPS 2025, CVPR 2025 (‚≠êÔ∏è Outstanding Reviewer), ICCV 2025, TPAMI 2024, ECCV 2024 (‚≠êÔ∏è Outstanding Reviewer), CVPR 2024, TPAMI 2023, TPAMI 2022

## üë®‚Äçüíª Work

**PhD Student, CV & NLP at UBC** \
_Vancouver | May 2024 - Present_ \
Working on multimodal vision-language models, commonsense reasoning, bias and fairness.

**Visiting Researcher, Toyota Technological Institute at Chicago** \
_Chicago | Oct 2024 - Dec 2024_ \
Worked on bias mitigation in image generation models.

**Research Intern, Borealis AI, RBC** \
_Vancouver | September 2022 - March 2023_ \
Worked on event time-series representation learning with transformers.

**Graduate Research Assistant, Computer Vision Lab at UBC Computer Science** \
_Vancouver | May 2022 - April 2024_ \
Visual Question Answering with external commonsense knowledge.

**Undergraduate Research Assistant, Computer Vision Lab at UBC** \
_Vancouver | May 2020 - August 2020_ \
Structured attention for vision-text transformer models to improve image grounding.

**Undergraduate Research Assistant, LEAP Project at UBC Computer Science** \
_Vancouver | May 2020 - August 2020_ \
Backend (RedCap Data) projects for LEAP, a differential privacy-focused federated ML platform.

**Machine Learning Engineer (Co-op), Hypercontext (prev. SoapBox)** \
_Toronto | May 2019 - August 2019_ \
Developed machine learning models for text classification, sentiment analysis and entity recognition using PyTorch, fast.ai and RASA NLU. This work is used in the [Meeting Insights](https://hypercontext.com/features/meeting-insights) feature of the product!

**Junior Software Developer (Co-op), AppNeta** \
_Vancouver | September 2018 ‚Äì April 2019_ \
Worked in a team of eight to scale up our application for cloud deployments. 

<!-- ## üë®‚Äçüéì Education

**PhD in Computer Vision and NLP** \
The University of British Columbia |
2024 onwards \
Four Year Fellowship (4YF) Recipient

**MSc. in Computer Science** \
The University of British Columbia |
2021 - 2024

**BSc. Honours in Computer Science** \
The University of British Columbia | 
2016 - 2021 |  GPA: 88% \
International Student ‚Äì Faculty of Science Scholarship & Dean‚Äôs Honour List -->


<!-- ## üì∏ Other

* Find my photography work on [Instagram](https://www.instagram.com/jpgs.by.adi/) and [Unsplash](https://unsplash.com/@adityachinchure)
* In the news: [Vancouver‚Äôs realtors are people too, say trio behind @realtorsofvancouver](https://www.vancouverisawesome.com/local-news/vancouvers-realtors-people-1936819) -->
